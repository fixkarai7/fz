import nltk
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lex_rank import LexRankSummarizer
from transformers import pipeline

nltk.download('punkt')

text = """Artificial Intelligence (AI) allows machines to learn from data and make decisions.
It helps industries solve problems, understand language, images, and human behavior."""

# Extractive Summary
parser = PlaintextParser.from_string(text, Tokenizer("english"))
extractive = ' '.join(str(s) for s in LexRankSummarizer()(parser.document, 2))

# Abstractive Summary
abstractive = pipeline("summarization")(text, max_length=60, min_length=5, do_sample=False)[0]['summary_text']

print("===Extractive Summary===\n", extractive)
print("\n===Abstractive Summary===\n", abstractive)
